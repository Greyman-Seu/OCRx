# 验证码实验

## 1.总体规划

| 工作内容                                           | 进度 | 完成情况                 | 备注         |
| -------------------------------------------------- | ---- | ------------------------ | ------------ |
| 调通github代码                                     |      |                          |              |
| 灰度图全字符模型训练（10w,31w）                    |      | 全准确率，字符准确率，   | 31w-70+  80+ |
| [-] rgb颜色识别模型训练(10w)                       |      | 全准确率，单个颜色准确率 |              |
| [*] rgb红字符模型训练                              |      |                          |              |
| 双头部颜色字符模型训练(10w)（20200707）(multitask) |      |                          |              |
| 数据分析脚本编写（原始字符，错误字符）             |      |                          |              |
| 字符切割并单字符分类模型（20200709）               |      |                          |              |
| openvino部署模型                                   |      |                          |              |
| ncnn部署模型                                       |      |                          |              |
| 修改backbone模型-resnet（20200708）                |      |                          |              |
| 修改resize模块（20200708）                         |      |                          |              |
| 爬虫数据，调整后看tsne的距离                       |      |                          |              |



1.path_10w_text: rgb 10w 预测字符   resize

2.path_10w_text: crop

3.path_10w_text: 模型变小





这本来就是一个信息爆炸的年代，请不要往网上丢东西。





## 2.详细记录

> 使用代码为crnn.pytorch

### 2.1 实验1 - 灰度图

> 判断灰度图识别验证码的准确率
>
> 推理：应该比

（单个字符）

nvidia-smi的信息

训练时长信息

准确率信息

测试样例:

### 2.2 实验2 - 转为红色图

### 2.x 修改resize模块

> 目的：现有的方案为将原图（35，95）直接resize到（32，100）。验证码特点：居中显示，且背景复杂，字符交叠。可尝试直接将resize改为crop方式，将原图修改为（32，95），或者先crop为（32，95）->使用后序填充padding为（32，100）。保持原图文字结构不变。







# CRNN 解读和代码

## 1. LSTM详解

> https://www.cnblogs.com/wangduo/p/6773601.html

1. 为什么可以长短记忆

   这边应该是添加了c,c步骤里面有遗忘步骤，与当前序列特征相加的过程，就没有其他过程了，便于长期记录

   但是rnn，传递的h，h是经过非线性变化的得到的，所以容易丢失信息。

2. 与rnn的区别

3. 为什么用tanh

## 2.CRNN详解

### 2.1 Introductin

1. 任务是STR任务

2. 相比常规的目标检测任务来说，STR作为序列检测需预测一系列的目标标签。此外，从instance角度出发，序列主体不定长，常规的DCNN无法直接应用到序列预测上面（由于DCNN必须输入输出尺寸固定）。

3. 与传统方法对比

   3.1分割后DCNN识别过于依赖于分割结果。

   3.2DCNN直接分类，英文共计90K分类，一是模型大，二是你那一迁移到中文任务中，因为中文组合远超1million规模


4. RNN优势是可以训练预测过程中无需知道序列目标图片的位置信息，但是前处理是必须要的，即将图片转换为图特征的序列。此前方式都是预处理无法与RNN构成端端训练。

5. CRNN 优势
1） 直接学习序列标签，无需其他细节的标注
2） 与DCNN一样具备强大的特征抽取能力，不需要手工特征工程或预处理步骤
3） 与RNN一样可以产生序列标签
4） 可以实现不定长识别，仅需高度归一化
5） 超过其他方法的准确率
6） 相比DCNN参数量小很多

### 2.2 模型结构

![image-20200711095507693](md_img\image-20200711095507693.png)

三阶段：CNN->RNN->解码   全部复用一个loss

#### 2.2.1 特征抽取

1.预测前，高度全部缩放到统一尺寸

2.CNN抽取参数，将高度方向压缩为一个像素，也即是cnn输出维度为（batch_size,C,1,W），后成一个2维平面，并以宽度作为序列长度使用。每个序列对应原图具备一些感受野

![image-20200711102307965](md_img\image-20200711102307965.png)

#### 2.2 序列化标签

使用RNN的优势：

1.RNN天然具有对上下文信息捕捉的能力，有助于识别稳定。引入上下文信息利于识别混淆字符例如“il”（不知道后面实验有没有让这句话立住）。

2.RNN支持梯度反传，可以组成端端模型。

3.可以处理不定长序列。








